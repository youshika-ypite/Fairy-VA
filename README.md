# Miko!! Голосовой ассистент

Проект основан на способе генерации речи TTS: [RVC-tts-webui](https://github.com/litagin02/rvc-tts-webui)

Только в разработке, много функций отсутствуют, возможности:
* Открытие найденных, утвержденных программ (точность совпадений 60-70%)
* Открытие браузера и заготовленных ссылок из файла
* Управление окнами активных приложений (точность совпадений ~75%)
* Использование локальной модели Llama3.1 для генерации ответов (необходимо установить модель)
* Уточнит время, погоду, дату (для погоды стоит указать настройки OpenWeatherMap)
* Не привязан к имени, можно задать любое имя, главное легко произносимое

Распознает только русский язык хоть и присутствует локализация приложения

На фоне с играми, вероятно генерировать текст и голос не сможет, однако можно отключить эту функцию и просто оставить ассистента для остальных задач, разговаривать не будет но работать должен.

В планах:
* Поменять дизайн
* Добавить локализацию на английский для ассистента
* Улучшить алгоритмы (мне нужно учится..)

Буду экспериментировать с методами распознавания, чтобы не тыркать микрофон каждые 2 секунды и систему воском не нагружать

Я считаю что задача минимум сделана, начал этот проект в конце августа 2024, сейчас 23 октября. Буду улучшать и потихоньку доделывать цели из плана, возможно добавлять новое.

## Установка

Тестировалось на Python 3.10 и pip 21.3.1 на Windows 11, работоспособнасть на этих версиях гарантирована.

Возможно, придется установить Microsoft C++ Build Tools, но я не уверен.

Microsoft C++ Build Tools: [Download installer](https://visualstudio.microsoft.com/ja/thank-you-downloading-visual-studio/?sku=BuildTools&rel=16).

```bash
git clone https://github.com/youshika-ypite/Miko-voice.git

# В директории проекта
curl -L -O https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/hubert_base.pt
curl -L -O https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/rmvpe.pt

# Создание виртуального окружения
python -m venv venv
venv\Scripts\activate

# Если видеокарта NVIDIA, устанавливаем
#   CUDA https://developer.nvidia.com/cuda-12-4-0-download-archive?target_os=Windows&target_arch=x86_64
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# Модули
pip install -r requirements.txt
```

## Установка Llama

Берем столько, сколько можем и просто не выключаем [Llama3.1](https://ollama.com/library/llama3.1)
У меня 32gb ОЗУ и 6gb видеопамяти, использую 8B версию.

## Расположение моделей

Расположите ваши модели в соответствии с этой схемой:
```bash
weights
├── model1
│   ├── my_model1.pth
│   └── my_index_file_for_model1.index
└── model2
    ├── my_model2.pth
    └── my_index_file_for_model2.index
```
Каждый каталог модели должен содержать ровно один файл `.pth` и не более одного файла `.index`. Имя директории
используется как имя модели.

Возникло впечатление, что в путях с не ASCII символами (например, `weights/モデル1/index.index`) происходят
ошибки faiss. Поэтому, пожалуйста, избегайте их.

## Перемещение конфигов

Переместите или скопируйте все .json файлы из `configs/default` в `configs/`

# Запуск 

Запустите скрипт main.py из виртуального окружения.
Наслаждайтесь.

### Донат

Поддержать меня можно здесь - [Boosty](https://boosty.to/ypite/donate)
